# ğŸ¯ AI Meeting Assistant Lean

> **Asistente de IA para reuniones 100% local, enfocado en privacidad y comunicaciÃ³n no-violenta usando el framework AEIOU**

[![Python](https://img.shields.io/badge/Python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![Status](https://img.shields.io/badge/Status-En%20Desarrollo-yellow.svg)](#roadmap)
[![Offline](https://img.shields.io/badge/Offline-100%25-brightgreen.svg)](#caracterÃ­sticas-principales)

## ğŸŒŸ CaracterÃ­sticas Principales

- **ğŸ”’ 100% Local y Privado**: Todo funciona offline, sin APIs externas
- **ğŸ¤ Reconocimiento de Voz Personal**: Diferencia automÃ¡ticamente tu voz de otros participantes
- **ğŸ’¬ Framework AEIOU**: Sugerencias especializadas en comunicaciÃ³n no-violenta
- **âš¡ Sin GPU Requerida**: Optimizado para CPUs estÃ¡ndar (4GB RAM)
- **ğŸš€ Desarrollo Lean**: MVP en 4 semanas, arquitectura simple y efectiva
- **ğŸ’° Costo Cero**: Sin suscripciones, sin APIs pagadas, compra Ãºnica

## ğŸ¯ Propuesta de Valor

**El primer asistente de IA que:**
- Escucha todas las reuniones sin necesidad de integrarse a plataformas especÃ­ficas
- Identifica tu perfil de voz pregrabado para diferenciarte de otros hablantes
- Genera sugerencias en tiempo real usando el framework AEIOU para comunicaciÃ³n constructiva
- Funciona completamente offline preservando tu privacidad total

## ğŸ—ï¸ Arquitectura TÃ©cnica

```mermaid
graph LR
    A[Audio Sistema] --> B[IdentificaciÃ³n Voz]
    B --> C{Â¿Es tu voz?}
    C -->|SÃ­| D[STT Local]
    C -->|No| E[Contexto]
    D --> F[AnÃ¡lisis IA]
    E --> F
    F --> G[Sugerencias AEIOU]
    G --> H[Overlay UI]
```

### Stack TecnolÃ³gico

| Componente | TecnologÃ­a | TamaÃ±o | PropÃ³sito |
|------------|------------|---------|-----------|
| **Audio Capture** | `sounddevice` + `numpy` | ~10MB | Captura audio del sistema |
| **Speaker ID** | `resemblyzer` | ~50MB | IdentificaciÃ³n de voz personal |
| **STT** | `whisper.cpp` | ~300MB | TranscripciÃ³n local |
| **IA** | `ollama` + `Qwen 2.5 0.5B` | ~1GB | GeneraciÃ³n de sugerencias |
| **UI** | `tkinter` / `PyQt6` | Built-in | Overlay system-wide |

## ğŸš€ Roadmap de Desarrollo

### ğŸ“… Semana 1: Audio Foundation
- [x] Setup del repositorio y estructura inicial
- [ ] Implementar captura de audio del sistema (WASAPI/Core Audio)
- [ ] Integrar Resemblyzer para embeddings de voz
- [ ] Sistema de calibraciÃ³n/entrenamiento de perfil personal
- [ ] Testing bÃ¡sico de identificaciÃ³n de speaker

**Entregable:** App que identifica tu voz vs otros en tiempo real

### ğŸ“… Semana 2: STT + IA Local
- [ ] Integrar Whisper.cpp para transcripciÃ³n local
- [ ] Setup Ollama con Qwen 2.5 0.5B
- [ ] Pipeline de procesamiento en tiempo real
- [ ] Manejo de buffers y optimizaciÃ³n de latencia

**Entregable:** TranscripciÃ³n en tiempo real diferenciando hablantes

### ğŸ“… Semana 3: AEIOU Intelligence
- [ ] Prompts especializados para detectar tensiÃ³n/conflicto
- [ ] Implementar framework AEIOU en el modelo
- [ ] LÃ³gica de cuÃ¡ndo mostrar sugerencias
- [ ] Context management para conversaciones

**Entregable:** Sugerencias AEIOU relevantes al contexto

### ğŸ“… Semana 4: UI + Packaging
- [ ] Overlay system-wide con transparencia
- [ ] UX/UI para mostrar sugerencias
- [ ] Packaging con PyInstaller para distribuciÃ³n
- [ ] Testing y optimizaciÃ³n de performance

**Entregable:** AplicaciÃ³n instalable y lista para uso

## ğŸ”§ InstalaciÃ³n y Setup

### Requerimientos del Sistema

- **Sistema Operativo:** Windows 10+, macOS 10.15+, Ubuntu 20.04+
- **RAM:** 4GB mÃ­nimo (recomendado 8GB)
- **CPU:** Intel i5 2018+ o AMD Ryzen 5 equivalente
- **Almacenamiento:** 2GB espacio libre
- **Audio:** Dispositivo de audio activo

### InstalaciÃ³n para Desarrollo

```bash
# Clonar el repositorio
git clone https://github.com/reyer3/ai-meeting-assistant-lean.git
cd ai-meeting-assistant-lean

# Crear entorno virtual
python -m venv venv
source venv/bin/activate  # Linux/Mac
# o
venv\Scripts\activate  # Windows

# Instalar dependencias
pip install -r requirements.txt

# Setup inicial (descarga modelos)
python setup.py install_models
```

### Primera ConfiguraciÃ³n

```bash
# Crear perfil de voz personal (una sola vez)
python src/voice_profile_setup.py

# Ejecutar la aplicaciÃ³n
python src/main.py
```

## ğŸ§  Framework AEIOU

El sistema estÃ¡ especializado en el framework AEIOU para comunicaciÃ³n no-violenta:

- **A (Acknowledge)**: Reconoce la perspectiva del otro
- **E (Express)**: Expresa tu posiciÃ³n con "yo siento/pienso"
- **I (Identify)**: PropÃ³n una soluciÃ³n especÃ­fica
- **O (Outcome)**: Define el resultado deseado para todos
- **U (Understanding)**: Busca comprensiÃ³n mutua

### Ejemplo de Sugerencia

**Contexto detectado:** TensiÃ³n en la conversaciÃ³n
**Ãšltimo comentario:** "No estÃ¡s entendiendo el punto principal del proyecto"

**Sugerencia AEIOU generada:**
```
ğŸ’¡ "Entiendo que sientes que no estoy captando algo importante (A). 
Yo percibo que hay diferentes perspectivas sobre el enfoque (E). 
Â¿PodrÃ­as ayudarme a entender especÃ­ficamente quÃ© aspecto te preocupa mÃ¡s? (I)
Mi objetivo es que ambos estemos alineados en la direcciÃ³n del proyecto (O).
Â¿QuÃ© informaciÃ³n adicional necesitas de mi parte? (U)"
```

## ğŸ“Š Performance Targets

| MÃ©trica | Target | MediciÃ³n |
|---------|--------|----------|
| IdentificaciÃ³n de voz | <100ms | Tiempo de embedding |
| TranscripciÃ³n (3s audio) | <2s | Whisper processing |
| GeneraciÃ³n IA | <3s | Respuesta AEIOU |
| **Latency total** | **<5s** | Audio â†’ Sugerencia |

## ğŸ”’ Privacidad y Seguridad

### Principios de Privacidad
- **Zero Cloud**: NingÃºn dato sale del dispositivo
- **Perfil Local**: Tu voz queda encriptada localmente
- **Sin TelemetrÃ­a**: No recopilamos estadÃ­sticas de uso
- **Open Source**: CÃ³digo auditable y transparente

### Datos Almacenados Localmente
- Perfil de voz personal (50KB encriptado)
- Configuraciones de la aplicaciÃ³n
- Logs temporales de debugging (opcional)

## ğŸ› ï¸ Estructura del Proyecto

```
ai-meeting-assistant-lean/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ audio/
â”‚   â”‚   â”œâ”€â”€ capture.py          # Captura audio del sistema
â”‚   â”‚   â””â”€â”€ speaker_id.py       # IdentificaciÃ³n de voz
â”‚   â”œâ”€â”€ ai/
â”‚   â”‚   â”œâ”€â”€ stt.py             # Speech-to-text local
â”‚   â”‚   â”œâ”€â”€ llm.py             # Modelo de IA local
â”‚   â”‚   â””â”€â”€ aeiou.py           # Framework AEIOU
â”‚   â”œâ”€â”€ ui/
â”‚   â”‚   â”œâ”€â”€ overlay.py         # Overlay system-wide
â”‚   â”‚   â””â”€â”€ settings.py        # Configuraciones
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ pipeline.py        # Pipeline principal
â”‚   â”‚   â””â”€â”€ config.py          # ConfiguraciÃ³n global
â”‚   â””â”€â”€ main.py                # Punto de entrada
â”œâ”€â”€ models/                    # Modelos IA locales
â”œâ”€â”€ tests/                     # Tests unitarios
â”œâ”€â”€ docs/                      # DocumentaciÃ³n
â”œâ”€â”€ requirements.txt           # Dependencias Python
â”œâ”€â”€ setup.py                   # Script de instalaciÃ³n
â””â”€â”€ README.md                  # Este archivo
```

## ğŸ¤ Contribuir al Proyecto

### Ãreas donde Necesitamos Ayuda

- **ğŸ¤ Audio Processing**: OptimizaciÃ³n de captura y filtrado
- **ğŸ§  AI Prompting**: Mejora de prompts para AEIOU
- **ğŸ¨ UI/UX**: DiseÃ±o de overlay no-intrusivo
- **ğŸ§ª Testing**: Testing en diferentes sistemas operativos
- **ğŸ“š DocumentaciÃ³n**: GuÃ­as de usuario y tÃ©cnicas

### CÃ³mo Contribuir

1. Fork el proyecto
2. Crea una branch para tu feature (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la branch (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request

### Desarrollo Local

```bash
# Instalar dependencias de desarrollo
pip install -r requirements-dev.txt

# Ejecutar tests
pytest tests/

# Linting
flake8 src/
black src/

# Type checking
mypy src/
```

## ğŸ“ˆ MÃ©tricas de Ã‰xito

- **PrecisiÃ³n Speaker ID**: >90% en condiciones normales
- **Latencia Total**: <5 segundos audio â†’ sugerencia
- **Memoria Usage**: <2GB durante operaciÃ³n
- **CPU Usage**: <30% en CPU promedio
- **Uptime**: >99% sin crashes durante 8 horas uso

## ğŸ†š ComparaciÃ³n con Competidores

| Feature | Este Proyecto | Otter.ai | Grain | Fireflies |
|---------|---------------|----------|--------|-----------|
| **100% Local** | âœ… | âŒ | âŒ | âŒ |
| **Sin SuscripciÃ³n** | âœ… | âŒ | âŒ | âŒ |
| **Speaker Recognition** | âœ… | âœ… | âœ… | âœ… |
| **AEIOU Framework** | âœ… | âŒ | âŒ | âŒ |
| **Tiempo Real** | âœ… | âœ… | âŒ | âŒ |
| **Sin Integraciones** | âœ… | âŒ | âŒ | âŒ |

## ğŸ“‹ TODO

### PrÃ³ximas Features
- [ ] Soporte para mÃºltiples idiomas
- [ ] Exportar sugerencias a PDF/texto
- [ ] IntegraciÃ³n con calendarios para contexto
- [ ] Modo "presentaciÃ³n" (solo escucha)
- [ ] Dashboard de mÃ©tricas de comunicaciÃ³n
- [ ] Plugin para Obsidian/Notion

### Optimizaciones TÃ©cnicas
- [ ] CuantizaciÃ³n INT8 para modelos mÃ¡s rÃ¡pidos
- [ ] GPU acceleration opcional (CUDA/Metal)
- [ ] Streaming processing para latencia ultra-baja
- [ ] Cache inteligente de embeddings

## ğŸ“œ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT - ver el archivo [LICENSE](LICENSE) para detalles.

## ğŸ™ Agradecimientos

- **OpenAI Whisper** - STT de alta calidad
- **Resemblyzer** - Embeddings de voz eficientes  
- **Ollama** - Runtime local para LLMs
- **AEIOU Framework** - MetodologÃ­a de comunicaciÃ³n no-violenta

## ğŸ“ Contacto

- **GitHub Issues**: Para bugs y feature requests
- **GitHub Discussions**: Para preguntas y ideas
- **Email**: [tu-email] (para temas privados)

---

**â­ Si este proyecto te resulta Ãºtil, considera darle una estrella en GitHub!**

---

*Desarrollado con â¤ï¸ para mejorar la comunicaciÃ³n en equipos de trabajo*