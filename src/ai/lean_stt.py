"""
Speech-to-Text optimizado para desarrollo lean
Enfoque: Transcripci√≥n local r√°pida usando Whisper small/base
"""

import asyncio
import time
import tempfile
import os
from typing import Optional, Dict, Any
from pathlib import Path

import numpy as np
import whisper
from loguru import logger
import soundfile as sf


class WhisperSTT:
    """
    STT lean usando Whisper local
    Optimizado para velocidad con modelos peque√±os
    """
    
    def __init__(self, model_size: str = "base", language: str = "es"):
        self.model_size = model_size
        self.language = language
        self.model = None
        self.sample_rate = 16000
        
        # Configuraci√≥n lean para velocidad
        self.transcribe_options = {
            "language": language,
            "task": "transcribe",
            "verbose": False,
            "condition_on_previous_text": False,  # M√°s r√°pido
            "temperature": 0.0,  # Determin√≠stico
            "compression_ratio_threshold": 2.4,
            "no_speech_threshold": 0.6,
            "logprob_threshold": -1.0
        }
        
        logger.info(f"üó£Ô∏è WhisperSTT lean inicializado: modelo {model_size}")
    
    async def initialize(self) -> bool:
        """Inicializa el modelo Whisper"""
        try:
            logger.info(f"üì• Cargando modelo Whisper {self.model_size}...")
            
            # Cargar en thread pool para no bloquear async
            loop = asyncio.get_event_loop()
            self.model = await loop.run_in_executor(
                None, 
                whisper.load_model, 
                self.model_size
            )
            
            logger.success(f"‚úÖ Modelo Whisper {self.model_size} cargado")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Error cargando Whisper: {e}")
            logger.info("üí° Instalar con: pip install openai-whisper")
            return False
    
    async def transcribe(self, audio_data: np.ndarray) -> Optional[str]:
        """
        Transcribe audio usando Whisper
        
        Args:
            audio_data: Array de audio (16kHz, mono)
            
        Returns:
            Texto transcrito o None si falla
        """
        
        if self.model is None:
            if not await self.initialize():
                return None
        
        start_time = time.time()
        
        try:
            # Verificar que el audio tenga contenido
            if len(audio_data) == 0:
                return None
            
            # Normalizar audio
            audio_data = self._preprocess_audio(audio_data)
            
            # Verificar nivel de audio (evitar transcribir silencio)
            rms_level = np.sqrt(np.mean(audio_data**2))
            if rms_level < 0.01:  # Umbral de silencio
                logger.debug("üîá Audio demasiado bajo, omitiendo transcripci√≥n")
                return None
            
            # Transcribir en thread pool
            loop = asyncio.get_event_loop()
            result = await loop.run_in_executor(
                None,
                self._transcribe_sync,
                audio_data
            )
            
            processing_time = time.time() - start_time
            
            if result and result["text"].strip():
                text = result["text"].strip()
                logger.debug(f"üìù Transcrito en {processing_time:.2f}s: {text[:50]}...")
                return text
            else:
                logger.debug("üîá No se detect√≥ habla")
                return None
                
        except Exception as e:
            logger.error(f"‚ùå Error en transcripci√≥n: {e}")
            return None
    
    def _transcribe_sync(self, audio_data: np.ndarray) -> Dict[str, Any]:
        """Transcripci√≥n s√≠ncrona para ejecutar en thread pool"""
        return self.model.transcribe(audio_data, **self.transcribe_options)
    
    def _preprocess_audio(self, audio_data: np.ndarray) -> np.ndarray:
        """Preprocesa audio para optimizar transcripci√≥n"""
        
        # Asegurar formato correcto
        if len(audio_data.shape) > 1:
            audio_data = audio_data.flatten()
        
        # Convertir a float32 si es necesario
        if audio_data.dtype != np.float32:
            audio_data = audio_data.astype(np.float32)
        
        # Normalizar al rango [-1, 1]
        max_val = np.max(np.abs(audio_data))
        if max_val > 0:
            audio_data = audio_data / max_val * 0.95
        
        # Pad o trim a m√∫ltiplo de 16000 (1 segundo m√≠nimo)
        min_length = self.sample_rate  # 1 segundo
        if len(audio_data) < min_length:
            # Pad con ceros
            audio_data = np.pad(audio_data, (0, min_length - len(audio_data)))
        elif len(audio_data) > self.sample_rate * 30:  # M√°ximo 30 segundos
            # Trim audio muy largo
            audio_data = audio_data[:self.sample_rate * 30]
        
        return audio_data
    
    async def transcribe_file(self, file_path: str) -> Optional[str]:
        """Transcribe archivo de audio"""
        
        try:
            # Cargar archivo
            audio_data, sr = sf.read(file_path)
            
            # Resampleas si es necesario
            if sr != self.sample_rate:
                import librosa
                audio_data = librosa.resample(audio_data, orig_sr=sr, target_sr=self.sample_rate)
            
            return await self.transcribe(audio_data)
            
        except Exception as e:
            logger.error(f"‚ùå Error transcribiendo archivo {file_path}: {e}")
            return None
    
    async def test_transcription(self, test_text: str = "Hola, esto es una prueba de transcripci√≥n") -> Dict[str, Any]:
        """Test de transcripci√≥n con audio sint√©tico"""
        
        try:
            # Generar audio de prueba (silencio con un poco de ruido)
            duration = 3  # segundos
            test_audio = np.random.normal(0, 0.1, self.sample_rate * duration).astype(np.float32)
            
            # Agregar "habla" sint√©tica (ondas sinusoidales)
            t = np.linspace(0, duration, self.sample_rate * duration)
            speech_signal = (
                0.3 * np.sin(2 * np.pi * 200 * t) +  # Fundamental
                0.2 * np.sin(2 * np.pi * 400 * t) +  # Primer arm√≥nico
                0.1 * np.sin(2 * np.pi * 600 * t)    # Segundo arm√≥nico
            )
            
            # Mezclar con ruido
            test_audio = 0.7 * speech_signal + 0.3 * test_audio
            
            start_time = time.time()
            result = await self.transcribe(test_audio)
            processing_time = time.time() - start_time
            
            return {
                "success": result is not None,
                "transcribed_text": result,
                "processing_time": processing_time,
                "audio_duration": duration,
                "model_size": self.model_size
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "model_size": self.model_size
            }
    
    def get_model_info(self) -> Dict[str, Any]:
        """Obtiene informaci√≥n del modelo"""
        
        model_info = {
            "model_size": self.model_size,
            "language": self.language,
            "sample_rate": self.sample_rate,
            "model_loaded": self.model is not None
        }
        
        if self.model is not None:
            # Informaci√≥n adicional si el modelo est√° cargado
            model_info.update({
                "model_dimensions": getattr(self.model, 'dims', None),
                "transcribe_options": self.transcribe_options
            })
        
        return model_info
    
    async def cleanup(self):
        """Limpia recursos del modelo"""
        if self.model is not None:
            # Whisper no requiere limpieza espec√≠fica
            self.model = None
            logger.info("üßπ Modelo Whisper limpiado")


# Factory function para configuraci√≥n lean
def create_lean_stt(model_size: str = "base", language: str = "es") -> WhisperSTT:
    """
    Factory para crear STT con configuraci√≥n lean
    
    Modelos disponibles por tama√±o y velocidad:
    - tiny: ~32MB, ~5x faster, menor precisi√≥n
    - base: ~74MB, ~3x faster, buena precisi√≥n (RECOMENDADO para lean)
    - small: ~244MB, ~2x faster, muy buena precisi√≥n
    - medium: ~769MB, ~1.5x faster, excelente precisi√≥n
    """
    return WhisperSTT(model_size, language)


if __name__ == "__main__":
    """Test del STT lean"""
    
    async def test_lean_stt():
        logger.info("üß™ Iniciando test de STT lean...")
        
        # Crear STT con modelo base (recomendado para lean)
        stt = create_lean_stt("base", "es")
        
        # Mostrar info del modelo
        model_info = stt.get_model_info()
        logger.info(f"üìä Info del modelo:")
        for key, value in model_info.items():
            logger.info(f"   {key}: {value}")
        
        # Test de transcripci√≥n
        logger.info("üé§ Ejecutando test de transcripci√≥n...")
        
        test_result = await stt.test_transcription()
        
        logger.info("üìã Resultado del test:")
        for key, value in test_result.items():
            logger.info(f"   {key}: {value}")
        
        if test_result["success"]:
            logger.success("‚úÖ STT funcionando correctamente")
        else:
            logger.error("‚ùå STT fall√≥ en el test")
        
        # Cleanup
        await stt.cleanup()
        
        logger.success("‚úÖ Test completado")
    
    asyncio.run(test_lean_stt())
